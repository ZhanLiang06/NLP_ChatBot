{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a8f729-2b0c-4896-8fbc-1c4b9151db09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import streamlit as st\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.llms import Ollama\n",
    "from langchain.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1380c28e-26ea-4d0b-a9dc-ea98d98959c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH    = \"ml.pdf\"  #change ur pdf name \n",
    "LOCAL_MODEL = \"llama3\"\n",
    "EMBEDDING   = \"nomic-embed-text\"\n",
    "# nomic-embed-text has higher context length and better than OpenAI eh text-embedding-ada-002 nd text-embedding-3-small\n",
    "# ^^ https://www.nomic.ai/blog/posts/nomic-embed-text-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad1b765-2dbc-442c-909c-a28de8366882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the pdf\n",
    "loader = PyPDFLoader(FILEPATH)\n",
    "data = loader.load()\n",
    "\n",
    "# tokenizeeeeeeeeee\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, chunk_overlap=100)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6fc7ea7-c332-4c5f-89fe-e3951056208a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22980\\586441589.py:7: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding=OllamaEmbeddings(model=EMBEDDING),\n"
     ]
    }
   ],
   "source": [
    "# Convert into embeddings and store them \n",
    "persist_directory = 'data' #ensures that the embeddings are available for future use, even after the scripts stop \n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits, \n",
    "    collection_name=\"rag_chroma\",\n",
    "    embedding=OllamaEmbeddings(model=EMBEDDING),\n",
    "    persist_directory=persist_directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3c4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing \n",
    "# model_local = ChatOllama(model=\"llama3\")\n",
    "\n",
    "# before_rag = \"What is {topic}\"\n",
    "# b4_rag_prompt = ChatPromptTemplate.from_template(before_rag)\n",
    "# b4_rag_chain = b4_rag_prompt | model_local | StrOutputParser()\n",
    "# print(b4_rag_chain.invoke({\"topic\":\"Ollama\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663e103f-b668-4b9b-8fe3-1c00ff15cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22980\\514830643.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(base_url=\"http://localhost:11434\",\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22980\\514830643.py:1: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = Ollama(base_url=\"http://localhost:11434\",\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(base_url=\"http://localhost:11434\",\n",
    "                                  model=LOCAL_MODEL,\n",
    "                                  verbose=True,\n",
    "                                  callback_manager=CallbackManager(\n",
    "                                      [StreamingStdOutCallbackHandler()])\n",
    "                                  )\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b03e7e2-0491-434f-9924-d1c7bf4147e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22980\\91073125.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\" \n",
    "    Context: {context}\n",
    "    History: {history}\n",
    "\n",
    "    User: {question}\n",
    "    Chatbot:\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "        input_variables=[\"history\", \"context\", \"question\"],\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "        memory_key=\"history\",\n",
    "        return_messages=True,\n",
    "        input_key=\"question\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ff62cc-d711-420c-831a-65bc2a47502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type='stuff',\n",
    "            retriever=retriever,\n",
    "            verbose=True,\n",
    "            chain_type_kwargs={\n",
    "                \"verbose\": True,\n",
    "                \"prompt\": prompt,\n",
    "                \"memory\": memory,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f0f7ae7-29bc-48c2-9907-4cfc3b8aa495",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is classification\" # change your question\n",
    "# query += \". Only from this pdf. Keep it short\"\n",
    "# response = qa_chain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdfba610-9990-4997-af0d-eb72a30f6245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m \n",
      "    Context: GB RAM.  \n",
      "The Implementation results are shown in Figure 6. Initially, the input images are preprocessed, then f eatures are \n",
      "extracted using pretrained CNN. Finally, classification is performed using SVM classifier.\n",
      "\n",
      "Nawal Soliman ALKolifi ALEnezi  / Procedia Computer Science 163 (2019) 85–92 87\n",
      " \n",
      " \n",
      "Author name / Procedia Computer Science 00 (2019) 000–000 3 \n",
      " \n",
      " \n",
      " \n",
      "4. Methodology \n",
      " \n",
      "In this section, the methodology of the proposed system for detection , extraction and classification of skin \n",
      "diseases images is described. The system will help significantly in the detection of melanoma, Eczema and Psoriasis. \n",
      "The whole architecture can be divided into several modules comprising of preprocessing, feature ext raction, and \n",
      "classification. The block diagram of the system is shown in Fig 2.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Fig. 2. The proposed system block diagram. \n",
      " \n",
      " \n",
      "4.1. Preprocessing: \n",
      " \n",
      "Achieving high performance of skin disease detection system requires overcoming so me major difficulties. Such \n",
      "as creating a database and unifying image dimensions. In the following section, the technique used in image \n",
      "resizing is explained. \n",
      " \n",
      " Image Resizing:\n",
      " \n",
      "To resolve the problem of different image sizes in the database an input image is either increase or decrease in \n",
      "size. Unifying the image size will get the same number of features from all images. Moreover, resizing the image \n",
      "reduces processing time and thus increases system performance. Fig 3 shows the original image of size is \n",
      "260×325 pixels. Fig 4 shows the resized image with the new size of 227×227 pixels.\n",
      "\n",
      "[8] Krizhevsky, A., ILYA, S., & Geoffrey, E. (2012) “ImageNet Classification with Deep Convolutional Neural Networks.” Advances in \n",
      "Neural Information Processing Systems.  \n",
      "[9] Cristianini, N., Shawe, J., “Support Vector Machines”, 2000.  \n",
      "[10] SOMMERVILLE, I., “Software Engineering”. 9th .2011.\n",
      "\n",
      "plays a key role in helping to classify skin diseases. Computer vision has a role in the detection of skin dis eases in a variety of \n",
      "techniques. Due to deserts and hot weather, skin diseases are common in Saudi Arabia. This work contributes in the research o f \n",
      "skin disease detection. We proposed an image processing -based method to detect skin diseases. This method t akes the digital \n",
      "image of disease effect skin area, then use image analysis to identify the type of disease. Our proposed approach is simple, fast \n",
      "and does not require expensive equipment other than a camera and a computer. The approach works on the inputs  of a color \n",
      "image. Then resize the of the image to extract features using pretrained convolutional neural network. After that classified feature \n",
      "using Multiclass SVM. Finally, the results are shown to the user, including the type of disease, spread, and se verity. The system \n",
      "successfully detects 3 different types of skin diseases with an accuracy rate of 100%. \n",
      " \n",
      " \n",
      "© 2019 The Authors. Published by Elsevier B.V.  \n",
      "This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-\n",
      "review under responsibility of the scientific committee of the 16th International Learning & Technology Conference 2019. \n",
      " \n",
      "Keywords: Skin diseases; Image Processing; Computer Vision; Machine Learning.   \n",
      " \n",
      " \n",
      "1. Introduction\n",
      "    History: []\n",
      "\n",
      "    User: What is classification\n",
      "    Chatbot:\n",
      "    \u001b[0m\n",
      "You're asking what classification is!\n",
      "\n",
      "In the context of machine learning and computer science, classification refers to the process of assigning a class label or category to an input instance based on its features or characteristics.\n",
      "\n",
      "In simpler terms, imagine you have a bunch of different types of fruits (e.g., apples, bananas, oranges), and you want to create a system that can automatically identify which fruit is which based on its color, shape, size, and other characteristics. That's basically what classification is!\n",
      "\n",
      "In this specific context, the authors are using machine learning techniques, such as Support Vector Machines (SVMs), to classify skin disease images into one of three categories: melanoma, eczema, or psoriasis.\n",
      "\n",
      "Would you like me to explain more about SVMs or image processing in general?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is classification',\n",
       " 'result': \"You're asking what classification is!\\n\\nIn the context of machine learning and computer science, classification refers to the process of assigning a class label or category to an input instance based on its features or characteristics.\\n\\nIn simpler terms, imagine you have a bunch of different types of fruits (e.g., apples, bananas, oranges), and you want to create a system that can automatically identify which fruit is which based on its color, shape, size, and other characteristics. That's basically what classification is!\\n\\nIn this specific context, the authors are using machine learning techniques, such as Support Vector Machines (SVMs), to classify skin disease images into one of three categories: melanoma, eczema, or psoriasis.\\n\\nWould you like me to explain more about SVMs or image processing in general?\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb43c3-223d-41c6-82c9-3a277e13a0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
